{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# pandas and numpy for data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# automated feature engineering\n",
    "import featuretools as ft\n",
    "from featuretools import selection\n",
    "\n",
    "# Filter out pandas warnings\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# Set up default plot styles\n",
    "plt.rcParams['font.size'] = 26\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# small first 1000 rows (sorted by SK_ID_CURR) \n",
    "# This allows us to actually see the results in a reasonable amount of time! \n",
    "app_train = pd.read_csv('../input/application_train.csv').sort_values('SK_ID_CURR').reset_index().loc[:1000, :].drop(columns = ['index'])\n",
    "app_test = pd.read_csv('../input/application_test.csv').sort_values('SK_ID_CURR').reset_index().loc[:1000, :].drop(columns = ['index'])\n",
    "bureau = pd.read_csv('../input/bureau.csv').sort_values(['SK_ID_CURR', 'SK_ID_BUREAU']).reset_index().loc[:1000, :].drop(columns = ['index'])\n",
    "bureau_balance = pd.read_csv('../input/bureau_balance.csv').sort_values('SK_ID_BUREAU').reset_index().loc[:1000, :].drop(columns = ['index'])\n",
    "cash = pd.read_csv('../input/POS_CASH_balance.csv').sort_values(['SK_ID_CURR', 'SK_ID_PREV']).reset_index().loc[:1000, :].drop(columns = ['index'])\n",
    "credit = pd.read_csv('../input/credit_card_balance.csv').sort_values(['SK_ID_CURR', 'SK_ID_PREV']).reset_index().loc[:1000, :].drop(columns = ['index'])\n",
    "previous = pd.read_csv('../input/previous_application.csv').sort_values(['SK_ID_CURR', 'SK_ID_PREV']).reset_index().loc[:1000, :].drop(columns = ['index'])\n",
    "installments = pd.read_csv('../input/installments_payments.csv').sort_values(['SK_ID_CURR', 'SK_ID_PREV']).reset_index().loc[:1000, :].drop(columns = ['index'])\n",
    "\n",
    "chunk_size = len(app_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# all data\n",
    "app_train = pd.read_csv('../input/application_train.csv').sort_values('SK_ID_CURR').reset_index().drop(columns = ['index'])\n",
    "app_test = pd.read_csv('../input/application_test.csv').sort_values('SK_ID_CURR').reset_index().drop(columns = ['index'])\n",
    "bureau = pd.read_csv('../input/bureau.csv').sort_values(['SK_ID_CURR', 'SK_ID_BUREAU']).reset_index().drop(columns = ['index'])\n",
    "bureau_balance = pd.read_csv('../input/bureau_balance.csv').sort_values('SK_ID_BUREAU').reset_index().drop(columns = ['index'])\n",
    "cash = pd.read_csv('../input/POS_CASH_balance.csv').sort_values(['SK_ID_CURR', 'SK_ID_PREV']).reset_index().drop(columns = ['index'])\n",
    "credit = pd.read_csv('../input/credit_card_balance.csv').sort_values(['SK_ID_CURR', 'SK_ID_PREV']).reset_index().drop(columns = ['index'])\n",
    "previous = pd.read_csv('../input/previous_application.csv').sort_values(['SK_ID_CURR', 'SK_ID_PREV']).reset_index().drop(columns = ['index'])\n",
    "installments = pd.read_csv('../input/installments_payments.csv').sort_values(['SK_ID_CURR', 'SK_ID_PREV']).reset_index().drop(columns = ['index'])\n",
    "\n",
    "# 10 % of no of rows in the training data\n",
    "chunk_size = round(len(app_train) * 10 / 100)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of boolean variables:  33\n"
     ]
    }
   ],
   "source": [
    "# Properly Representing Variable Types\n",
    "\n",
    "\n",
    "app_types = {}\n",
    "# Iterate through the columns and record the Boolean columns\n",
    "for col in app_train:\n",
    "    # If column is a number with only two values, encode it as a Boolean\n",
    "    if (app_train[col].dtype != 'object') and (len(app_train[col].unique()) <= 2):\n",
    "        app_types[col] = ft.variable_types.Boolean\n",
    "\n",
    "print('Number of boolean variables: ', len(app_types))\n",
    "\n",
    "# Record ordinal variables\n",
    "app_types['REGION_RATING_CLIENT'] = ft.variable_types.Ordinal\n",
    "app_types['REGION_RATING_CLIENT_W_CITY'] = ft.variable_types.Ordinal\n",
    "\n",
    "app_test_types = app_types.copy()\n",
    "del app_test_types['TARGET']\n",
    "\n",
    "# Record boolean variables in the previous data\n",
    "previous_types= {'NFLAG_LAST_APPL_IN_DAY': ft.variable_types.Boolean,\n",
    "                 'NFLAG_INSURED_ON_APPROVAL': ft.variable_types.Boolean}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     0,
     3
    ]
   },
   "outputs": [],
   "source": [
    "# outliers\n",
    "# Replace all the day outliers\n",
    "\n",
    "def replace_day_outliers(df):\n",
    "    \"\"\"Replace 365243 with np.nan in any columns with DAYS\"\"\"\n",
    "    for col in df.columns:\n",
    "        if \"DAYS\" in col:\n",
    "            df[col] = df[col].replace({365243: np.nan})\n",
    "\n",
    "    return df\n",
    "\n",
    "app_train = replace_day_outliers(app_train)\n",
    "app_test = replace_day_outliers(app_test)\n",
    "bureau = replace_day_outliers(bureau)\n",
    "bureau_balance = replace_day_outliers(bureau_balance)\n",
    "credit = replace_day_outliers(credit)\n",
    "cash = replace_day_outliers(cash)\n",
    "previous = replace_day_outliers(previous)\n",
    "installments = replace_day_outliers(installments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# creating Time Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2016-01-01 00:00:00')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Establish a starting date for all applications at Home Credit\n",
    "start_date = pd.Timestamp(\"2016-01-01\")\n",
    "start_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# bureau\n",
    "\n",
    "# Convert to timedelta in days\n",
    "for col in ['DAYS_CREDIT', 'DAYS_CREDIT_ENDDATE', 'DAYS_ENDDATE_FACT', 'DAYS_CREDIT_UPDATE']:\n",
    "    bureau[col] = pd.to_timedelta(bureau[col], 'D')\n",
    "    \n",
    "\n",
    "# Create the date columns\n",
    "bureau['bureau_credit_application_date'] = start_date + bureau['DAYS_CREDIT']\n",
    "bureau['bureau_credit_end_date'] = start_date + bureau['DAYS_CREDIT_ENDDATE']\n",
    "bureau['bureau_credit_close_date'] = start_date + bureau['DAYS_ENDDATE_FACT']\n",
    "bureau['bureau_credit_update_date'] = start_date + bureau['DAYS_CREDIT_UPDATE']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# bureau_balance\n",
    "\n",
    "# Convert to timedelta\n",
    "bureau_balance['MONTHS_BALANCE'] = pd.to_timedelta(bureau_balance['MONTHS_BALANCE'], 'M')\n",
    "# Make a date column\n",
    "bureau_balance['bureau_balance_date'] = start_date + bureau_balance['MONTHS_BALANCE']\n",
    "bureau_balance = bureau_balance.drop(columns = ['MONTHS_BALANCE'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# previous\n",
    "\n",
    "# Convert to timedeltas in days\n",
    "for col in ['DAYS_DECISION', 'DAYS_FIRST_DRAWING', 'DAYS_FIRST_DUE', 'DAYS_LAST_DUE_1ST_VERSION', 'DAYS_LAST_DUE', \n",
    "            'DAYS_TERMINATION']:\n",
    "    previous[col] = pd.to_timedelta(previous[col], 'D')\n",
    "    \n",
    "# Make date columns\n",
    "previous['previous_decision_date'] = start_date + previous['DAYS_DECISION']\n",
    "previous['previous_drawing_date'] = start_date + previous['DAYS_FIRST_DRAWING']\n",
    "previous['previous_first_due_date'] = start_date + previous['DAYS_FIRST_DUE']\n",
    "previous['previous_last_duefirst_date'] = start_date + previous['DAYS_LAST_DUE_1ST_VERSION']\n",
    "previous['previous_last_due_date'] = start_date + previous['DAYS_LAST_DUE']\n",
    "previous['previous_termination_date'] = start_date + previous['DAYS_TERMINATION']\n",
    "\n",
    "# Drop the time offset columns\n",
    "previous = previous.drop(columns = ['DAYS_DECISION', 'DAYS_FIRST_DRAWING', 'DAYS_FIRST_DUE', 'DAYS_LAST_DUE_1ST_VERSION', \n",
    "                                    'DAYS_LAST_DUE', 'DAYS_TERMINATION'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# credit cash\n",
    "\n",
    "# Convert to timedelta objects\n",
    "credit['MONTHS_BALANCE'] = pd.to_timedelta(credit['MONTHS_BALANCE'], 'M')\n",
    "cash['MONTHS_BALANCE'] = pd.to_timedelta(cash['MONTHS_BALANCE'], 'M')\n",
    "\n",
    "# Make a date column\n",
    "credit['credit_balance_date'] = start_date + credit['MONTHS_BALANCE']\n",
    "credit = credit.drop(columns = ['MONTHS_BALANCE'])\n",
    "\n",
    "# Make a date column\n",
    "cash['cash_balance_date'] = start_date + cash['MONTHS_BALANCE']\n",
    "cash = cash.drop(columns = ['MONTHS_BALANCE'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# installments\n",
    "\n",
    "# Conver to time delta object\n",
    "installments['DAYS_INSTALMENT'] = pd.to_timedelta(installments['DAYS_INSTALMENT'], 'D')\n",
    "installments['DAYS_ENTRY_PAYMENT'] = pd.to_timedelta(installments['DAYS_ENTRY_PAYMENT'], 'D')\n",
    "\n",
    "# Create time column and drop\n",
    "installments['installments_due_date'] = start_date + installments['DAYS_INSTALMENT']\n",
    "installments = installments.drop(columns = ['DAYS_INSTALMENT'])\n",
    "\n",
    "installments['installments_paid_date'] = start_date + installments['DAYS_ENTRY_PAYMENT']\n",
    "installments = installments.drop(columns = ['DAYS_ENTRY_PAYMENT'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define structure "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Entities and Entitysets\n",
    "\n",
    "# Make an entityset\n",
    "es = ft.EntitySet(id = 'clients')\n",
    "\n",
    "# Entities with a unique index\n",
    "es = es.entity_from_dataframe(entity_id = 'app_train', dataframe = app_train, \n",
    "                              index = 'SK_ID_CURR', variable_types = app_types)\n",
    "\n",
    "es = es.entity_from_dataframe(entity_id = 'app_test', dataframe = app_test, \n",
    "                              index = 'SK_ID_CURR', variable_types = app_test_types)\n",
    "\n",
    "es = es.entity_from_dataframe(entity_id = 'bureau', dataframe = bureau, \n",
    "                              index = 'SK_ID_BUREAU', time_index='bureau_credit_application_date')\n",
    "\n",
    "es = es.entity_from_dataframe(entity_id = 'previous', dataframe = previous, \n",
    "                              index = 'SK_ID_PREV', time_index = 'previous_decision_date',\n",
    "                              variable_types = previous_types)\n",
    "\n",
    "# Entities that do not have a unique index\n",
    "es = es.entity_from_dataframe(entity_id = 'bureau_balance', dataframe = bureau_balance, \n",
    "                              make_index = True, index = 'bb_index',\n",
    "                              time_index = 'bureau_balance_date')\n",
    "\n",
    "es = es.entity_from_dataframe(entity_id = 'cash', dataframe = cash, \n",
    "                              make_index = True, index = 'cash_index',\n",
    "                              time_index = 'cash_balance_date')\n",
    "\n",
    "es = es.entity_from_dataframe(entity_id = 'installments', dataframe = installments,\n",
    "                              make_index = True, index = 'installments_index',\n",
    "                              time_index = 'installments_paid_date')\n",
    "\n",
    "es = es.entity_from_dataframe(entity_id = 'credit', dataframe = credit,\n",
    "                              make_index = True, index = 'credit_index',\n",
    "                              time_index = 'credit_balance_date')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Entityset: clients\n",
       "  Entities:\n",
       "    app_train [Rows: 307511, Columns: 122]\n",
       "    credit [Rows: 3840312, Columns: 24]\n",
       "    bureau_balance [Rows: 27299925, Columns: 4]\n",
       "    bureau [Rows: 1716428, Columns: 21]\n",
       "    app_test [Rows: 48744, Columns: 121]\n",
       "    installments [Rows: 13605401, Columns: 9]\n",
       "    cash [Rows: 10001358, Columns: 9]\n",
       "    previous [Rows: 1670214, Columns: 37]\n",
       "  Relationships:\n",
       "    bureau.SK_ID_CURR -> app_train.SK_ID_CURR\n",
       "    bureau.SK_ID_CURR -> app_test.SK_ID_CURR\n",
       "    bureau_balance.SK_ID_BUREAU -> bureau.SK_ID_BUREAU\n",
       "    previous.SK_ID_CURR -> app_train.SK_ID_CURR\n",
       "    previous.SK_ID_CURR -> app_test.SK_ID_CURR\n",
       "    cash.SK_ID_PREV -> previous.SK_ID_PREV\n",
       "    installments.SK_ID_PREV -> previous.SK_ID_PREV\n",
       "    credit.SK_ID_PREV -> previous.SK_ID_PREV"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Relationship\n",
    "\n",
    "# Relationship between app and bureau\n",
    "r_app_bureau = ft.Relationship(es['app_train']['SK_ID_CURR'], es['bureau']['SK_ID_CURR'])\n",
    "\n",
    "# Test Relationship between app and bureau\n",
    "r_test_app_bureau = ft.Relationship(es['app_test']['SK_ID_CURR'], es['bureau']['SK_ID_CURR'])\n",
    "\n",
    "# Relationship between bureau and bureau balance\n",
    "r_bureau_balance = ft.Relationship(es['bureau']['SK_ID_BUREAU'], es['bureau_balance']['SK_ID_BUREAU'])\n",
    "\n",
    "# Relationship between current app and previous apps\n",
    "r_app_previous = ft.Relationship(es['app_train']['SK_ID_CURR'], es['previous']['SK_ID_CURR'])\n",
    "\n",
    "# Test Relationship between current app and previous apps\n",
    "r_test_app_previous = ft.Relationship(es['app_test']['SK_ID_CURR'], es['previous']['SK_ID_CURR'])\n",
    "\n",
    "# Relationships between previous apps and cash, installments, and credit\n",
    "r_previous_cash = ft.Relationship(es['previous']['SK_ID_PREV'], es['cash']['SK_ID_PREV'])\n",
    "r_previous_installments = ft.Relationship(es['previous']['SK_ID_PREV'], es['installments']['SK_ID_PREV'])\n",
    "r_previous_credit = ft.Relationship(es['previous']['SK_ID_PREV'], es['credit']['SK_ID_PREV'])\n",
    "\n",
    "# Add in the defined relationships\n",
    "es = es.add_relationships([r_app_bureau, r_test_app_bureau, r_bureau_balance, r_app_previous, r_test_app_previous,\n",
    "                           r_previous_cash, r_previous_installments, r_previous_credit])\n",
    "# Print out the EntitySet\n",
    "es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# time_features\n",
    "time_features, time_feature_names = ft.dfs(entityset = es, target_entity = 'app_train', \n",
    "                                           trans_primitives = ['cum_sum', 'time_since_previous'], \n",
    "                                           max_depth = 2,\n",
    "                                           agg_primitives = ['trend'] ,\n",
    "                                           features_only = False, verbose = True,\n",
    "                                           chunk_size = chunk_size,\n",
    "                                           ignore_entities = ['app_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# interesting features\n",
    "# Assign interesting values\n",
    "es['previous']['NAME_CONTRACT_STATUS'].interesting_values = ['Approved', 'Refused', 'Canceled']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Calculate the features with intereseting values\n",
    "interesting_features, interesting_feature_names = ft.dfs(entityset=es, target_entity='app_train', \n",
    "                                                         max_depth = 1, \n",
    "                                                         where_primitives = ['mean', 'mode'], \n",
    "                                                         trans_primitives=[], \n",
    "                                                         features_only = False, verbose = True,\n",
    "                                                         chunk_size = chunk_size,\n",
    "                                                         ignore_entities = ['app_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# seed feature\n",
    "# Late Payment seed feature\n",
    "late_payment = ft.Feature(es['installments']['installments_due_date']) < ft.Feature(\n",
    "    es['installments']['installments_paid_date'])\n",
    "# Rename the feature\n",
    "late_payment = late_payment.rename(\"late_payment\")\n",
    "\n",
    "# Create a feed representing whether the loan is past due\n",
    "past_due = ft.Feature(es['bureau_balance']['STATUS']).isin(['1', '2', '3', '4', '5'])\n",
    "past_due = past_due.rename(\"past_due\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# DFS with seed features\n",
    "seed_features, seed_feature_names = ft.dfs(entityset = es,\n",
    "                                           target_entity = 'app_train',\n",
    "                                           agg_primitives = ['percent_true', 'mean'],\n",
    "                                           trans_primitives = [], \n",
    "                                           seed_features = [late_payment,past_due],\n",
    "                                           features_only = False, verbose = True,\n",
    "                                           chunk_size = chunk_size,\n",
    "                                           ignore_entities = ['app_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "code_folding": [
     0,
     2,
     18,
     41,
     70,
     78
    ]
   },
   "outputs": [],
   "source": [
    "# Custom Feature Primitives\n",
    "\n",
    "from featuretools.variable_types import (\n",
    "    Boolean, Datetime,\n",
    "    DatetimeTimeIndex,\n",
    "    Discrete,\n",
    "    Index,\n",
    "    Numeric,\n",
    "    Variable,\n",
    "    Id\n",
    ")\n",
    "\n",
    "from featuretools.primitives import AggregationPrimitive, make_agg_primitive\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "def normalized_mode_count(x):\n",
    "    \"\"\"\n",
    "    Return the fraction of total observations that \n",
    "    are the most common observation. For example, \n",
    "    in an array of ['A', 'A', 'A', 'B', 'B'], the \n",
    "    function will return 0.6.\"\"\"\n",
    "    \n",
    "    if x.mode().shape[0] == 0:\n",
    "        return np.nan\n",
    "            \n",
    "    # Count occurence of each value\n",
    "    counts = dict(Counter(x.values))\n",
    "    # Find the mode\n",
    "    mode = x.mode().iloc[0]\n",
    "    # Divide the occurences of mode by the total occurrences\n",
    "    return counts[mode] / np.sum(list(counts.values()))\n",
    "    \n",
    "\n",
    "NormalizedModeCount = make_agg_primitive(function = normalized_mode_count, \n",
    "                                         input_types = [Discrete],\n",
    "                                         return_type = Numeric)\n",
    "\n",
    "# Function from https://codereview.stackexchange.com/a/15095\n",
    "def longest_repetition(x):\n",
    "    \"\"\"\n",
    "    Returns the item with most consecutive occurrences in `x`. \n",
    "    If there are multiple items with the same number of conseqcutive occurrences,\n",
    "    it will return the first one. If `x` is empty, returns None. \n",
    "    \"\"\"\n",
    "    \n",
    "    x = x.dropna()\n",
    "    \n",
    "    if x.shape[0] < 1:\n",
    "        return None\n",
    "    \n",
    "    # Set the longest element\n",
    "    longest_element = current_element = None\n",
    "    longest_repeats = current_repeats = 0\n",
    "    \n",
    "    # Iterate through the iterable\n",
    "    for element in x:\n",
    "        if current_element == element:\n",
    "            current_repeats += 1\n",
    "        else:\n",
    "            current_element = element\n",
    "            current_repeats = 1\n",
    "        if current_repeats > longest_repeats:\n",
    "            longest_repeats = current_repeats\n",
    "            longest_element = current_element\n",
    "            \n",
    "    return longest_element\n",
    "\n",
    "LongestSeq = make_agg_primitive(function = longest_repetition,\n",
    "                                     input_types = [Discrete],\n",
    "                                     return_type = Discrete)    \n",
    "\n",
    "\n",
    "# Building on the Trend Aggregation Primitive\n",
    "# Copied from https://github.com/Featuretools/featuretools/blob/master/featuretools/primitives/aggregation_primitives.py\n",
    "\n",
    "def most_recent(y, x):\n",
    "    df = pd.DataFrame({\"x\": x, \"y\": y}).dropna()\n",
    "            \n",
    "    if df.shape[0] < 1:\n",
    "        return np.nan\n",
    "\n",
    "    # Sort the values by timestamps reversed\n",
    "    df = df.sort_values('x', ascending = False).reset_index()\n",
    "\n",
    "    # Return the most recent occurence\n",
    "    return df.iloc[0]['y']\n",
    "\n",
    "MostRecent = make_agg_primitive(function = most_recent,\n",
    "                                input_types = [Discrete, Datetime],\n",
    "                                return_type = Discrete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built 3343 features\n",
      "\n",
      "Elapsed: 00:00 | Remaining: ? | Progress:   0%|       | Calculated: 0/11 chunks"
     ]
    }
   ],
   "source": [
    "# Putting it all Together\n",
    "# train\n",
    "feature_matrix, feature_names = ft.dfs(entityset = es, target_entity = 'app_train',\n",
    "                                       agg_primitives = ['mean', 'max', 'min', 'trend', 'mode', \n",
    "                                                         'count', \n",
    "                                                         'sum', 'percent_true', NormalizedModeCount, \n",
    "                                                         MostRecent, LongestSeq],\n",
    "                                       trans_primitives = ['diff', 'cum_sum', 'cum_mean', \n",
    "                                                           'percentile'], \n",
    "                                       where_primitives = ['mean', 'sum'],\n",
    "                                       seed_features = [late_payment, past_due],\n",
    "                                       max_depth = 2, features_only = False, verbose = True,\n",
    "                                       chunk_size = chunk_size,\n",
    "                                       ignore_entities = ['app_test'])\n",
    "\n",
    "\n",
    "# test\n",
    "feature_matrix_test, feature_names_test = ft.dfs(entityset = es, target_entity = 'app_test',\n",
    "                                                   agg_primitives = ['mean', 'max', 'min', 'trend', \n",
    "                                                                     'mode', 'count', \n",
    "                                                                     'sum', 'percent_true', \n",
    "                                                                     NormalizedModeCount, \n",
    "                                                                     MostRecent, LongestSeq],\n",
    "                                                   trans_primitives = ['diff', 'cum_sum', 'cum_mean',\n",
    "                                                                       'percentile'], \n",
    "                                                   where_primitives = ['mean', 'sum'],\n",
    "                                                   seed_features = [late_payment, past_due],\n",
    "                                                   max_depth = 2, features_only = False, \n",
    "                                                 verbose = True,\n",
    "                                                   chunk_size = chunk_size,\n",
    "                                                   ignore_entities = ['app_train'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# remove features\n",
    "\n",
    "# Remove low information features\n",
    "feature_matrix2 = selection.remove_low_information_features(feature_matrix)\n",
    "print('Removed %d features from training features'  % (feature_matrix.shape[1] - feature_matrix2.shape[1]))\n",
    "\n",
    "feature_matrix_test2 = selection.remove_low_information_features(feature_matrix_test)\n",
    "print('Removed %d features from testing features' % (feature_matrix_test.shape[1] - feature_matrix_test2.shape[1]))\n",
    "\n",
    "train_labels = feature_matrix['TARGET']\n",
    "feature_matrix, feature_matrix_test = feature_matrix2.align(feature_matrix_test2, join = 'inner', axis = 1)\n",
    "feature_matrix['TARGET'] = train_labels\n",
    "\n",
    "print('Final training shape: ', feature_matrix.shape)\n",
    "print('Final testing shape: ', feature_matrix_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Save the feature matrix to a csv\n",
    "feature_matrix.to_csv('../output/feature_matrix.csv')\n",
    "feature_matrix_test.to_csv('../output/feature_matrix_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
